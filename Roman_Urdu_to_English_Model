{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8735372,"sourceType":"datasetVersion","datasetId":5243778},{"sourceId":8829630,"sourceType":"datasetVersion","datasetId":5312509}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mubashiriqbal1111/finetuned-t5base-romanurdu-to-english-translation2?scriptVersionId=186329737\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install torch torchvision transformers pytorch-lightning","metadata":{"_uuid":"60275104-cb29-49b1-9247-5932c0bfe5fe","_cell_guid":"bad7ca8f-835a-4856-9011-89a0d6110316","collapsed":false,"execution":{"iopub.status.busy":"2024-06-26T13:41:28.47398Z","iopub.execute_input":"2024-06-26T13:41:28.47438Z","iopub.status.idle":"2024-06-26T13:41:42.036452Z","shell.execute_reply.started":"2024-06-26T13:41:28.474344Z","shell.execute_reply":"2024-06-26T13:41:42.035073Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom transformers import T5Tokenizer,T5ForConditionalGeneration\nimport pytorch_lightning as pl\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer,AutoModel\nfrom datasets import load_dataset\nfrom torchmetrics.text.bleu import BLEUScore","metadata":{"_uuid":"ebc71f0e-3042-4598-98c9-9c948254b7b4","_cell_guid":"74c3e175-b72c-4cc2-838a-4f60f95ce380","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T07:48:57.091516Z","iopub.execute_input":"2024-07-01T07:48:57.091855Z","iopub.status.idle":"2024-07-01T07:48:57.097249Z","shell.execute_reply.started":"2024-07-01T07:48:57.091829Z","shell.execute_reply":"2024-07-01T07:48:57.096196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=320):\n        self.dataframe = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n#         dataset= self.dataframe[idx]\n        dataset = self.dataframe.iloc[idx]\n        source_text, target_text = str(dataset['roman_urdu']),str(dataset['english'])\n        source_tokenized = self.tokenizer.encode_plus(\n            source_text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        target_tokenized = self.tokenizer.encode(\n            target_text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': source_tokenized['input_ids'].squeeze(),\n            'attention_mask': source_tokenized['attention_mask'].squeeze(),\n            'labels': target_tokenized.squeeze()\n        }","metadata":{"_uuid":"591411ad-130e-4644-a2f9-560b4ee4b66d","_cell_guid":"cce195bc-5379-465c-a3da-04884dcbbd75","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T07:54:13.545035Z","iopub.execute_input":"2024-07-01T07:54:13.545411Z","iopub.status.idle":"2024-07-01T07:54:13.553644Z","shell.execute_reply.started":"2024-07-01T07:54:13.54538Z","shell.execute_reply":"2024-07-01T07:54:13.552582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetModule(pl.LightningDataModule):\n    \n    def __init__(self,train_frame,test_frame,tokenizer,batch_size=2):\n        self.train_frame = train_frame\n        self.test_frame = test_frame\n        self.tokenizer=tokenizer\n        self.batch_size =batch_size\n        self.prepare_data_per_node = False\n        self._log_hyperparams = False\n        self.allow_zero_length_dataloader_with_multiple_devices = False\n    \n    def setup(self,stage):\n        self.train_dataset = TranslationDataset(self.train_frame,self.tokenizer)\n        self.test_dataset = TranslationDataset(self.test_frame,self.tokenizer)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.test_dataset,batch_size=self.batch_size,shuffle=True)","metadata":{"_uuid":"2e4a2229-9787-4414-9945-f08d9848a981","_cell_guid":"6d1ee707-b36a-41e4-88cc-348fb4d98ebb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T07:54:13.555548Z","iopub.execute_input":"2024-07-01T07:54:13.555895Z","iopub.status.idle":"2024-07-01T07:54:13.569309Z","shell.execute_reply.started":"2024-07-01T07:54:13.555864Z","shell.execute_reply":"2024-07-01T07:54:13.568426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n    def __init__(self, model_name='t5-base', learning_rate=1e-4):\n        super().__init__()\n        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.learning_rate = learning_rate\n        self.bleu = BLEUScore()\n        self.train_losses = []\n\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        return self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n\n    def decoder(self, output):\n        if isinstance(output, torch.Tensor):  # Directly handle tensor input\n            decoded_texts = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in output]\n        else:  # Assume it's a Seq2SeqLMOutput object\n            logits = output.logits\n            predicted_ids = torch.argmax(logits, dim=-1)\n            decoded_texts = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in predicted_ids]\n        return decoded_texts\n        \n    def training_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['labels']\n\n        outputs = self.forward(input_ids, attention_mask, labels)\n        loss = outputs.loss\n        self.train_losses.append(loss)\n#         self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def on_train_epoch_end(self):\n        avg_loss = torch.stack(self.train_losses).mean()\n        self.log('train_loss', avg_loss, prog_bar=True)\n        self.train_losses.clear()\n        \n    def validation_step(self, batch, batch_idx):\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['labels']\n\n        outputs = self.forward(input_ids, attention_mask, labels)\n        val_loss = outputs.loss\n        output_decoded =  self.decoder(outputs)\n        target_decoded = self.decoder(labels)\n        self.bleu(output_decoded,target_decoded)\n        self.log('val_loss', val_loss, prog_bar=True)\n        self.log('Bleu_Score', self.bleu, prog_bar=True)\n        return val_loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:18.247965Z","iopub.execute_input":"2024-07-01T08:15:18.248664Z","iopub.status.idle":"2024-07-01T08:15:18.262414Z","shell.execute_reply.started":"2024-07-01T08:15:18.24863Z","shell.execute_reply":"2024-07-01T08:15:18.261483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef load_data():\n    data = pd.read_csv(\"/kaggle/input/roman-urdu-to-english/Final_data\")\n#     data.drop(columns=['SENTIMENT'],inplace=True)\n    data.rename(columns={\"Roman Urdu\":\"roman_urdu\",\n                         \"English\":\"english\"},inplace=True)\n#     data= Dataset.from_pandas(data)\n    \n    data.drop(columns=['Unnamed: 0'],inplace=True)\n    \n    data['roman_urdu'] = \"Translate from roman_urdu to english : \"+ data['roman_urdu']\n    train_data,test_data = train_test_split(data,test_size=0.03559)\n    \n    return train_data,test_data\n\ntrain_dataset, val_dataset = load_data()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:50:44.048376Z","iopub.execute_input":"2024-07-01T07:50:44.049027Z","iopub.status.idle":"2024-07-01T07:50:44.199284Z","shell.execute_reply.started":"2024-07-01T07:50:44.048992Z","shell.execute_reply":"2024-07-01T07:50:44.198532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from datasets import load_dataset\n\ndef load_data():\n    data = pd.read_csv(\"/kaggle/input/Roman Urdu reviews Dataset with English translation.csv\", encoding=\"MacRoman\")\n    data.drop(columns=['SENTIMENT'],inplace=True)\n    data.rename(columns={\"ROMAN URDU REVIEWS\":\"roman_urdu\",\n                         \"TRANSLATED IN ENGLISH \":\"english\"},inplace=True)\n#     data= Dataset.from_pandas(data)\n    \n    \n    \n    data['roman_urdu'] = \"Translate from roman_urdu to english : \"+ data['roman_urdu']\n    train_data,test_data = train_test_split(data,test_size=0.03559)\n    \n    return train_data,test_data\n\ntrain_dataset, val_dataset = load_data()","metadata":{"_uuid":"6556a024-1f27-4155-99e0-7d3b9f6b8064","_cell_guid":"775ef1aa-40b4-4c79-89f4-b785e4d214ac","jupyter":{"outputs_hidden":false,"source_hidden":true},"execution":{"iopub.status.busy":"2024-06-28T04:10:28.253467Z","iopub.execute_input":"2024-06-28T04:10:28.253815Z","iopub.status.idle":"2024-06-28T04:10:28.496119Z","shell.execute_reply.started":"2024-06-28T04:10:28.253792Z","shell.execute_reply":"2024-06-28T04:10:28.494421Z"}}},{"cell_type":"code","source":"checkpoint=\"google-t5/t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"_uuid":"738c81d5-546c-48e0-bf8f-d3ea48037d17","_cell_guid":"e999e71f-7a9f-4284-93c8-26a3f72d5a9c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T07:54:19.264082Z","iopub.execute_input":"2024-07-01T07:54:19.264464Z","iopub.status.idle":"2024-07-01T07:54:19.525736Z","shell.execute_reply.started":"2024-07-01T07:54:19.264437Z","shell.execute_reply":"2024-07-01T07:54:19.524712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_module = DatasetModule(train_dataset,val_dataset,tokenizer=tokenizer,batch_size=2)\nmodel = T5FineTuner()\ntrainer = pl.Trainer(accelerator='gpu',devices=1, min_epochs=3,max_epochs=15, precision='16-mixed')","metadata":{"_uuid":"3169a786-fc92-4eac-ae4a-dde893fca90b","_cell_guid":"03a041dd-76cf-41f7-8368-b5531d915ba3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T08:15:25.452438Z","iopub.execute_input":"2024-07-01T08:15:25.453158Z","iopub.status.idle":"2024-07-01T08:15:27.104571Z","shell.execute_reply.started":"2024-07-01T08:15:25.453114Z","shell.execute_reply":"2024-07-01T08:15:27.103831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model,data_module)","metadata":{"_uuid":"e02d3c66-65e8-4425-9dd2-04025cf0cf2d","_cell_guid":"40544e5d-35c8-4449-93d3-a219432447c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-07-01T08:15:37.677366Z","iopub.execute_input":"2024-07-01T08:15:37.677737Z","iopub.status.idle":"2024-07-01T08:15:38.86028Z","shell.execute_reply.started":"2024-07-01T08:15:37.677707Z","shell.execute_reply":"2024-07-01T08:15:38.859499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_ver2.pth')\n# !pip install chardet evaluate sacrebleu","metadata":{"_uuid":"8733d737-9cf8-4f5f-9104-dd01c902c7e0","_cell_guid":"c5bb107e-7be9-4d96-a403-c6d9078e4cf1","collapsed":false,"execution":{"iopub.status.busy":"2024-06-26T13:51:27.753934Z","iopub.execute_input":"2024-06-26T13:51:27.754987Z","iopub.status.idle":"2024-06-26T13:51:41.858828Z","shell.execute_reply.started":"2024-06-26T13:51:27.754949Z","shell.execute_reply":"2024-06-26T13:51:41.857312Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model = T5ForConditionalGeneration.from_pretrained('t5-base')\n# model.load_state_dict(torch.load('/kaggle/working/tuned_t5_base.pth'))\n\n# model.eval()\n\n# input_text = \"Your input text here\"\n# inputs = tokenizer(input_text, return_tensors=\"pt\")\n# outputs = model.generate(**inputs)\n\n# decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n# print(decoded_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T18:00:12.612574Z","iopub.execute_input":"2024-06-27T18:00:12.613315Z","iopub.status.idle":"2024-06-27T18:00:14.013483Z","shell.execute_reply.started":"2024-06-27T18:00:12.613283Z","shell.execute_reply":"2024-06-27T18:00:14.011314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}